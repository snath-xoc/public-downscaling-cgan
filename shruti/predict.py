import argparse
import datetime
import gc
import os
import pickle
import yaml

import cartopy.crs as ccrs
import matplotlib.pyplot as plt
import numpy as np
import numpy.ma as ma

# import matplotlib as mpl; mpl.use('svg')
import seaborn as sns
from matplotlib import colorbar, colors, gridspec
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.colors import ListedColormap

import data
import read_config
from data import all_fcst_fields, get_dates
from data_generator import DataGenerator as DataGeneratorFull
from evaluation import _init_VAEGAN
from noise import NoiseGenerator
from plots import plot_img_log_coastlines, truncate_colourmap
from rapsd import plot_spectrum1d, rapsd
from setupmodel import setup_model

read_config.set_gpu_mode()  # set up whether to use GPU, and mem alloc mode
downscaling_steps = read_config.read_downscaling_factor()["steps"]

# plotting parameters
value_range_precip = (0.1, 15.0)
value_range_orog = (0.0, 1.0e4)
cmap = ListedColormap(sns.color_palette("YlGnBu", 256))
cmap.set_under("white")
cmap.set_bad("black")
linewidth = 0.4
extent = [19.1, 54.3, -13.7, 24.7]  # left, right, bottom, top
alpha = 0.8
dpi = 200

# colorbar
units = "Rain rate [mm h$^{-1}$]"
cb_tick_loc = np.array([0.1, 0.5, 1, 2, 5, 15])
cb_tick_labels = [0.1, 0.5, 1, 2, 5, 15]

# colormap for LSM -- removes the white end
cmap_lsm = plt.get_cmap("terrain")
cmap_lsm = truncate_colourmap(cmap_lsm, 0, 0.8)

parser = argparse.ArgumentParser()
parser.add_argument(
    "--log_folder", type=str, help="directory where model weights are saved"
)
parser.add_argument(
    "--model_number", type=int, help="model iteration to load", default=313600
)
parser.add_argument("--predict_year", type=int, help="year to predict on", default=2019)
parser.add_argument(
    "--num_samples",
    type=int,
    help="number of images to generate predictions for",
    default=1,
)
parser.add_argument(
    "--pred_ensemble_size", type=int, help="size of prediction ensemble", default=3
)
parser.set_defaults(plot_all=False)
parser.add_argument(
    "--plot_all",
    dest="plot_all",
    action="store_true",
    help="Plot all GAN predictions separately, and plot power spectra",
)
args = parser.parse_args()

log_folder = args.log_folder
model_number = args.model_number
predict_year = args.predict_year
num_samples = args.num_samples
pred_ensemble_size = args.pred_ensemble_size

config_path = os.path.join(log_folder, "setup_params.yaml")
with open(config_path, "r") as f:
    try:
        setup_params = yaml.safe_load(f)
    except yaml.YAMLError as exc:
        print(exc)

mode = setup_params["GENERAL"]["mode"]
arch = setup_params["MODEL"]["architecture"]
padding = setup_params["MODEL"]["padding"]
problem_type = setup_params["GENERAL"]["problem_type"]
filters_gen = setup_params["GENERATOR"]["filters_gen"]
noise_channels = setup_params["GENERATOR"]["noise_channels"]
latent_variables = setup_params["GENERATOR"]["latent_variables"]
filters_disc = setup_params["DISCRIMINATOR"]["filters_disc"]
val_years = setup_params["VAL"]["val_years"]
constant_fields = 2

data_paths = read_config.get_data_paths()

batch_size = 1

weights_fn = os.path.join(log_folder, "models", f"gen_weights-{model_number:07}.h5")
dates = get_dates(predict_year, start_hour=0, end_hour=168)

assert problem_type == "normal"  # removed autocoarsen from this script

autocoarsen = False
plot_input_title = "Forecast"
input_channels = 4 * len(all_fcst_fields)

# load appropriate dataset
data_predict = DataGeneratorFull(
    dates=dates,
    fcst_fields=all_fcst_fields,
    start_hour=0,
    end_hour=168,
    batch_size=batch_size,
    log_precip=True,
    shuffle=True,
    constants=True,
    fcst_norm=True,
)


# initialise model
model = setup_model(
    mode=mode,
    arch=arch,
    downscaling_steps=downscaling_steps,
    input_channels=input_channels,
    constant_fields=constant_fields,
    filters_gen=filters_gen,
    filters_disc=filters_disc,
    noise_channels=noise_channels,
    latent_variables=latent_variables,
    padding=padding,
)
gen = model.gen
if mode == "VAEGAN":
    _init_VAEGAN(gen, data_predict, batch_size, latent_variables)
gen.load_weights(weights_fn)

# dataset for benchmarks - not currently used
# data_benchmarks = DataGeneratorFull(dates=dates,
#                                     fcst_fields=data.all_fcst_fields,
#                                     start_hour=0,
#                                     end_hour=168,
#                                     batch_size=batch_size,
#                                     log_precip=False,
#                                     shuffle=True,
#                                     fcst_norm=False)

tpidx_mean = 4 * all_fcst_fields.index("tp")  # 4*idx is tp ens mean,
tpidx_stdev = 4 * all_fcst_fields.index("tp") + 1  # 4*idx+1 is tp ens stdev

pred = []
seq_real = []
seq_cond = []
seq_const = []
dates_save = []
hours_save = []
data_predict_iter = iter(data_predict)

for ii in range(num_samples):
    inputs, outputs = next(data_predict_iter)

    dates_save.append(data_predict.dates[ii])
    hours_save.append(data_predict.time_idxs[ii])

    # store denormalised inputs, outputs, predictions
    seq_const.append(inputs["hi_res_inputs"])
    input_conditions = inputs["lo_res_inputs"].copy()

    # denormalise precip inputs for plotting
    input_conditions[..., tpidx_mean] = data.denormalise(
        inputs["lo_res_inputs"][..., tpidx_mean]
    )
    input_conditions[..., tpidx_stdev] = data.denormalise(
        inputs["lo_res_inputs"][..., tpidx_stdev]
    )

    seq_cond.append(input_conditions)

    truth = outputs["output"]
    mask = outputs["mask"]
    masked_truth = ma.array(truth, mask=mask)

    # make sure ground truth image has correct dimensions
    sample = np.expand_dims(masked_truth, axis=-1)
    seq_real.append(data.denormalise(sample))

    print(f"sample number {ii+1}")
    print(f"max truth value is {np.max(seq_real[-1])}")

    pred_ensemble = []
    if mode == "det":  # this is plotting det as a model
        pred_ensemble_size = 1  # can't generate an ensemble with deterministic method
        pred_ensemble.append(
            data.denormalise(gen.predict(inputs))
        )  # pretend it's an ensemble so dims match
        pred.append(np.array(pred_ensemble))
    else:
        if mode == "GAN":
            noise_shape = inputs["lo_res_inputs"][0, ..., 0].shape + (noise_channels,)
            noise_gen = NoiseGenerator(noise_shape, batch_size=batch_size)
        elif mode == "VAEGAN":
            noise_shape = inputs["lo_res_inputs"][0, ..., 0].shape + (latent_variables,)
            noise_gen = NoiseGenerator(noise_shape, batch_size=batch_size)
        if mode == "VAEGAN":
            # call encoder once
            mean, logvar = gen.encoder(
                [inputs["lo_res_inputs"], inputs["hi_res_inputs"]]
            )
        for jj in range(pred_ensemble_size):
            inputs["noise_input"] = noise_gen()
            if mode == "GAN":
                gan_inputs = [
                    inputs["lo_res_inputs"],
                    inputs["hi_res_inputs"],
                    inputs["noise_input"],
                ]
                pred_ensemble.append(data.denormalise(gen.predict(gan_inputs)))
            elif mode == "VAEGAN":
                dec_inputs = [
                    mean,
                    logvar,
                    inputs["noise_input"],
                    inputs["hi_res_inputs"],
                ]
                pred_ensemble.append(data.denormalise(gen.decoder.predict(dec_inputs)))
            print(f"max predicted value is {np.max(pred_ensemble[-1])}")
        pred.append(np.array(pred_ensemble))

# not used, but could also generate comparison plots of benchmark approaches
# data_benchmarks_iter = iter(data_benchmarks)
# for ii in range(num_samples):
#     inp, outp = next(data_benchmarks_iter)

# plot examples of input fields and predictions
for ii in range(num_samples):
    # len(seq_foo) = num_samples
    # seq[ii].shape = [NHWC], C=input_channels for cond, C=2 for const, C=1 for real, pred
    fcst_total_mean = seq_cond[ii][0, ..., tpidx_mean]
    fcst_total_stdev = seq_cond[ii][0, ..., tpidx_stdev]

    constant_0 = seq_const[ii][0, ..., 0]  # orog
    constant_0 *= 10000.0  # undo orography normalisation
    # constant_1 = seq_const[ii][0, ..., 1]  # lsm

    truth = seq_real[ii][0, :, :, 0]
    pred_0 = pred[ii][0, 0, :, :, 0]  # [sample_images][pred_ensemble_size, N, H, W, C]
    pred_mean = pred[ii][:, 0, :, :, 0].mean(axis=0)  # mean of ensemble members

    # bring precip plots away from 0, since colour scale is logarithmic, and 0 values
    # get confused with NaNs once the log is done
    fcst_total_mean = np.maximum(fcst_total_mean, 1e-6)
    fcst_total_stdev = np.maximum(fcst_total_stdev, 1e-6)
    truth = np.maximum(truth, 1e-6)
    pred_0 = np.maximum(pred_0, 1e-6)
    pred_mean = np.maximum(pred_mean, 1e-6)

    # list of precip-related colorbars
    cbs = []

    plt.figure(figsize=(8, 7), dpi=200)
    # calculate forecast date and valid time, for plot title
    fcst_date = datetime.datetime.strptime(dates_save[ii], "%Y%m%d")
    valid_dt = fcst_date + datetime.timedelta(
        hours=int(hours_save[ii]) * data.HOURS
    )  # needs to change for 12Z forecasts
    title = (
        f"Forecast {dates_save[ii]}, valid starting {valid_dt.strftime('%Y%m%d %H')}Z"
    )
    plt.suptitle(title, fontsize=16)

    # set up sub-plots
    gs = gridspec.GridSpec(2, 3)
    ax1 = plt.subplot(gs[0, 0], projection=ccrs.PlateCarree())
    ax2 = plt.subplot(gs[0, 1], projection=ccrs.PlateCarree())
    ax3 = plt.subplot(gs[0, 2])
    ax4 = plt.subplot(gs[1, 0], projection=ccrs.PlateCarree())
    ax5 = plt.subplot(gs[1, 1], projection=ccrs.PlateCarree())
    ax6 = plt.subplot(gs[1, 2], projection=ccrs.PlateCarree())
    ax = [ax1, ax2, ax3, ax4, ax5, ax6]

    fcst_tmean_ax = ax[0].imshow(
        fcst_total_mean,
        norm=colors.LogNorm(*value_range_precip),
        cmap=cmap,
        origin="lower",
        extent=extent,
        transform=ccrs.PlateCarree(),
        alpha=alpha,
    )
    ax[0].set_title("Forecast - tp mean")
    ax[0].coastlines(resolution="10m", color="black", linewidth=linewidth)
    cbs.append(
        plt.colorbar(
            fcst_tmean_ax,
            ax=ax[0],
            norm=colors.LogNorm(*value_range_precip),
            orientation="horizontal",
            fraction=0.035,
            pad=0.04,
        )
    )

    fcst_tstd_ax = ax[1].imshow(
        fcst_total_stdev,
        norm=colors.LogNorm(*value_range_precip),
        cmap=cmap,
        origin="lower",
        extent=extent,
        transform=ccrs.PlateCarree(),
        alpha=alpha,
    )
    ax[1].set_title("Forecast - tp stdev")
    ax[1].coastlines(resolution="10m", color="black", linewidth=linewidth)
    cbs.append(
        plt.colorbar(
            fcst_tstd_ax,
            ax=ax[1],
            norm=colors.LogNorm(*value_range_precip),
            orientation="horizontal",
            fraction=0.035,
            pad=0.04,
        )
    )

    OROG = ax[2].imshow(constant_0, cmap="terrain", origin="lower", alpha=alpha)
    ax[2].set_title("Orography")
    foo = plt.colorbar(
        OROG,
        ax=ax[2],
        norm=colors.Normalize(*value_range_orog),
        orientation="horizontal",
        fraction=0.04,
        pad=0.04,
    )
    foo.set_label("Elevation [m]", size=8)

    TRUTH = ax[3].imshow(
        truth,
        norm=colors.LogNorm(*value_range_precip),
        cmap=cmap,
        origin="lower",
        extent=extent,
        transform=ccrs.PlateCarree(),
        alpha=alpha,
    )
    ax[3].set_title("Ground truth")
    ax[3].coastlines(resolution="10m", color="black", linewidth=linewidth)
    cbs.append(
        plt.colorbar(
            TRUTH,
            ax=ax[3],
            norm=colors.LogNorm(*value_range_precip),
            orientation="horizontal",
            fraction=0.035,
            pad=0.04,
        )
    )

    PRED = ax[4].imshow(
        pred_0,
        norm=colors.LogNorm(*value_range_precip),
        cmap=cmap,
        origin="lower",
        extent=extent,
        transform=ccrs.PlateCarree(),
        alpha=alpha,
    )
    ax[4].set_title("GAN - example prediction")
    ax[4].coastlines(resolution="10m", color="black", linewidth=linewidth)
    cbs.append(
        plt.colorbar(
            PRED,
            ax=ax[4],
            norm=colors.LogNorm(*value_range_precip),
            orientation="horizontal",
            fraction=0.035,
            pad=0.04,
        )
    )

    PRED_mean = ax[5].imshow(
        pred_mean,
        norm=colors.LogNorm(*value_range_precip),
        cmap=cmap,
        origin="lower",
        extent=extent,
        transform=ccrs.PlateCarree(),
        alpha=0.8,
    )
    ax[5].set_title("GAN - mean prediction")
    ax[5].coastlines(resolution="10m", color="black", linewidth=linewidth)
    cbs.append(
        plt.colorbar(
            PRED_mean,
            ax=ax[5],
            norm=colors.LogNorm(*value_range_precip),
            orientation="horizontal",
            fraction=0.035,
            pad=0.04,
        )
    )

    for ax_ in ax:
        ax_.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)
        ax_.tick_params(labelsize=8)

    for cb in cbs:
        cb.set_ticks(cb_tick_loc)
        cb.set_ticklabels(cb_tick_labels)
        cb.set_label(units, size=8)

    # cannot save as pdf - will produce artefacts
    plt.savefig(
        os.path.join(
            log_folder,
            f"prediction-and-inputs-{model_number}-{data_predict.seed}-{ii}.png",
        ),
        bbox_inches="tight",
    )
    plt.close()

if args.plot_all:
    # generate labels for plots
    labels = ["Forecast", "TRUTH"]
    for ii in range(pred_ensemble_size):
        labels.append(f"{mode} pred {ii+1}")

    # plot a range of prediction examples for different downscaling methods
    sequences = []
    for ii in range(num_samples):
        tmp = {}
        tmp["TRUTH"] = np.maximum(seq_real[ii][0, ..., 0], 1e-6)
        tmp["Forecast"] = np.maximum(seq_cond[ii][0, ..., tpidx_mean], 1e-6)
        tmp["dates"] = dates_save[ii]
        tmp["time_idxs"] = hours_save[ii]
        for jj in range(pred_ensemble_size):
            tmp[f"{mode} pred {jj+1}"] = np.maximum(pred[ii][jj][0, ..., 0], 1e-6)
        sequences.append(tmp)

    fname = "sequences-" + str(model_number) + "-" + str(num_samples) + ".pickle"
    fnamefull = os.path.join(log_folder, fname)

    with open(fnamefull, "wb") as f:
        pickle.dump(sequences, f)

    num_cols = num_samples
    num_rows = len(labels)
    spacing = 10
    plt.figure(figsize=(1.5 * num_cols, 1.5 * num_rows), dpi=300)

    gs = gridspec.GridSpec(
        spacing * num_rows + 1, spacing * num_cols, wspace=0.5, hspace=0.5
    )

    for kk in range(num_samples):
        for ii in range(len(labels)):
            plt.subplot(
                gs[
                    (spacing * ii) : (spacing + spacing * ii),
                    (spacing * kk) : (spacing + spacing * kk),
                ],
                projection=ccrs.PlateCarree(),
            )
            ax = plt.gca()
            ax.coastlines(resolution="10m", color="black", linewidth=linewidth)
            plot_img_log_coastlines(
                sequences[kk][labels[ii]],
                value_range_precip=value_range_precip,
                cmap=cmap,
                extent=extent,
                alpha=alpha,
            )
            if ii == 0:
                title = (
                    dates_save[kk][:4]
                    + "-"
                    + dates_save[kk][4:6]
                    + "-"
                    + dates_save[kk][6:8]
                    + " "
                    + str(hours_save[kk])
                    + " time period"
                )
                plt.title(title, fontsize=9)

            if kk == 0:
                ax.set_ylabel(labels[ii])  # cartopy takes over the xlabel and ylabel
                ax.set_yticks([])  # this weird hack restores them. WHY?!?!

    plt.suptitle("Example predictions for different input conditions")

    cax = plt.subplot(gs[-1, 1:-1]).axes
    cb = colorbar.ColorbarBase(
        cax,
        norm=colors.LogNorm(*value_range_precip),
        cmap=cmap,
        orientation="horizontal",
    )
    cb.set_ticks(cb_tick_loc)
    cb.set_ticklabels(cb_tick_labels)
    cax.tick_params(labelsize=12)
    cb.set_label(units, size=12)

    # cannot save as pdf - will produce artefacts
    plt.savefig(
        os.path.join(log_folder, f"predictions-{model_number}-{data_predict.seed}.png"),
        bbox_inches="tight",
    )
    plt.close()
    gc.collect()

# power spectrum plots
if args.plot_all:
    # colours = ['plum', 'palevioletred', 'lightslategrey', 'coral', 'lightblue', 'darkseagreen', 'mediumturquoise', 'purple', 'navy']
    plt.style.use("seaborn-colorblind")
    colours = plt.rcParams["axes.prop_cycle"].by_key()["color"]
    plot_scales = [512, 256, 128, 64, 32, 16, 8, 4]
    # create a PdfPages object to save multiple plots to same pdf
    pdf = PdfPages(
        os.path.join(log_folder, f"RAPSD-{model_number}-{data_predict.seed}.pdf")
    )

    for kk in range(num_samples):
        fig, ax = plt.subplots()
        # this iterates over the minimum of len(labels) [pred_ensemble_size + 2]
        # and colours [6], i.e., it will show at most 4 GAN predictions
        for ii, color in zip(range(len(labels)), colours):
            R_1, freq_1 = rapsd(
                sequences[kk][labels[ii]], fft_method=np.fft, return_freq=True
            )
            # Plot the observed power spectrum and the model
            plot_spectrum1d(
                freq_1,
                R_1,
                x_units="km",
                y_units="dBR",
                color=color,
                ax=ax,
                label=labels[ii],
                wavelength_ticks=plot_scales,
            )

            plt.legend()

        ax.set_title(f"Radially averaged log-power spectrum - {kk+1}")
        # save the current figure
        pdf.savefig(fig)
    plt.close()
    pdf.close()
